{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>ML DSL in Action</center></h1>\n",
    "\n",
    "Google Cloud Platform: \n",
    "1. Google Dataproc\n",
    "2. Google Cloud Storage\n",
    "3. Google AI Platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import com.griddynamics.dsl.ml.mldsl as mldsl\n",
    "from com.griddynamics.dsl.ml.settings.profiles import PySparkJobProfile, AIProfile, DeployAIProfile\n",
    "from com.griddynamics.dsl.ml.settings.description import Platform\n",
    "\n",
    "import importlib\n",
    "import os\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Sequences from Original Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I went and saw this movie last night after being coaxed to by a few friends of mine. I'll admit that I was reluctant to see it because from what I knew of Ashton Kutcher he was only able to do comedy. I was wrong. Kutcher played the character of Jake Fischer very well, and Kevin Costner played Ben Randall with such professionalism. The sign of a good movie is that it can toy with our emotions. This one did exactly that. The entire theater (which was sold out) was overcome by laughter during the first half of the movie, and were moved to tears during the second half. While exiting the theater I not only saw many women in tears, but many full grown men as well, trying desperately not to let anyone see them crying. This movie was great, and I suggest that you go see it before you judge."
     ]
    }
   ],
   "source": [
    "!head -n 20 dev/aclImdb/test/pos/0_10.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer to Create Sequences "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute Tokenizer on ML Platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words saved to: \"demo/20-06-25-14-56-27/words\"\n",
      "Train saved to: \"demo/20-06-25-14-56-27/train\"\n",
      "Test saved to: \"demo/20-06-25-14-56-27/test\"\n",
      "Local SparkContext has been stopped automatically\n",
      "Temporary path: /home/jovyan/work/data/.mldsl/text_tokenizer.py\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<com.griddynamics.dsl.ml.py_script.PyScript at 0x7f7391369080>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%py_script -e --name text_tokenizer.py --path demo/scripts --train_path dev/aclImdb/train/ --test_path dev/aclImdb/test/ --word_embeds dev/glove.6B.50d.txt -o demo\n",
    "#!/usr/bin/python\n",
    "\n",
    "from pyspark import SQLContext, SparkContext\n",
    "from pyspark.sql.window import Window\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import StringType, ArrayType, IntegerType, FloatType\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "import argparse\n",
    "\n",
    "\n",
    "def read_glove_vecs(glove_file, output_path):\n",
    "    rdd = sc.textFile(glove_file)\n",
    "    row = Row(\"glovevec\")\n",
    "    df = rdd.map(row).toDF()\n",
    "    split_col = F.split(F.col('glovevec'), \" \")\n",
    "    df = df.withColumn('word', split_col.getItem(0))\n",
    "    df = df.withColumn('splitted', split_col)\n",
    "    vec_udf = F.udf(lambda row: [float(i) for i in row[1:]], ArrayType(FloatType()))\n",
    "    df = df.withColumn('vec', vec_udf(F.col('splitted')))\n",
    "    df = df.drop('splitted', \"glovevec\")\n",
    "    w = Window.orderBy([\"word\"])\n",
    "    qdf = df.withColumn('vec', F.concat_ws(',', 'vec')).withColumn(\"id\", F.row_number().over(w))\n",
    "    \n",
    "    path = '{}/words'.format(output_path)\n",
    "    qdf.coalesce(1).write.format('csv').option(\"sep\",\"\\t\").option('header', 'true').save(path)\n",
    "    print('Words saved to: \"{}\"'.format(path))\n",
    "    list_words = list(map(lambda row: row.asDict(), qdf.collect()))\n",
    "    word_to_vec_map = {item['word']: item['vec'] for item in list_words}\n",
    "    words_to_index = {item['word']:item[\"id\"] for item in list_words}\n",
    "    index_to_words = {item[\"id\"]: item['word'] for item in list_words}\n",
    "    return words_to_index, index_to_words, word_to_vec_map\n",
    "\n",
    "\n",
    "def prepare_df(path, const, words_dct):\n",
    "    rdd = sc.textFile(path)\n",
    "    row = Row(\"review\")\n",
    "    df = rdd.map(row).toDF()\n",
    "    # Clean text\n",
    "    df_clean = df.select(F.lower(F.regexp_replace(F.col('review'), \"n't\", \" n't\")).alias('review'))\n",
    "    df_clean = df_clean.select(F.lower(F.regexp_replace(F.col('review'), \n",
    "                                                        \"[^0-9a-zA-Z\\\\s]\", \"\")).alias('review'))\n",
    "    # Tokenize text\n",
    "    tokenizer = Tokenizer(inputCol='review', outputCol='words_token')\n",
    "    df_words_token = tokenizer.transform(df_clean).select('words_token')\n",
    "    df_cutted = df_words_token.withColumn('length', F.size(F.col('words_token')))\n",
    "    # Replace word with it's index\n",
    "    word_udf = F.udf(lambda row: [words_to_index[w] if w in words_to_index.keys() else words_to_index[\"unk\"] for w in row],\n",
    "                 ArrayType(IntegerType()))\n",
    "    df_stemmed = df_cutted.withColumn('words_stemmed', word_udf(F.col('words_token')))\n",
    "    return df_stemmed.withColumn(\"class\", F.lit(const))\n",
    "\n",
    "\n",
    "def save_dataset(df_pos, df_neg, path):\n",
    "    df = df_pos.union(df_neg)\n",
    "    w = Window.orderBy([\"words_stemmed\"])\n",
    "    df = df.withColumn(\"review_id\", F.row_number().over(w)).withColumn('int_seq',\n",
    "                                                                       F.concat_ws(',', 'words_stemmed'))\n",
    "    qdf = df.select(['review_id', 'int_seq', 'class'])\n",
    "    qdf.coalesce(1).write.format('csv').option('header', 'true').save(path)\n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--train_path', type=str, help=\"train positive reviews path\")\n",
    "    parser.add_argument('--test_path', type=str, help=\"test positive reviews path\")\n",
    "    parser.add_argument('--word_embeds', type=str, help=\"Path to glove word embeddings\")\n",
    "    parser.add_argument('--output_path', type=str, help=\"Sequences output path\")\n",
    "    \n",
    "\n",
    "    args, d = parser.parse_known_args()\n",
    "    output_path = args.output_path\n",
    "    SparkContext.setSystemProperty('spark.sql.broadcastTimeout', '36000')\n",
    "    sc = SparkContext(appName=\"word_tokenizer\").getOrCreate()\n",
    "    sql = SQLContext(sc)\n",
    "\n",
    "    words_to_index, index_to_words, word_to_vec_map = read_glove_vecs(args.word_embeds, output_path)\n",
    "    reviews_filter = '999*.txt'\n",
    "    df_pos = prepare_df(f\"{args.train_path}/pos/{reviews_filter}\", 1, words_to_index)\n",
    "    df_neg = prepare_df(f\"{args.train_path}/neg/{reviews_filter}\", 0, words_to_index)\n",
    "    train_path = '{}/train'.format(output_path)\n",
    "    save_dataset(df_pos, df_neg, train_path)\n",
    "    print('Train saved to: \"{}\"'.format(train_path))\n",
    "\n",
    "    df_pos = prepare_df(f\"{args.test_path}/pos/{reviews_filter}\", 1, words_to_index)\n",
    "    df_neg = prepare_df(f\"{args.test_path}/neg/{reviews_filter}\", 0, words_to_index)\n",
    "    test_path = '{}/test'.format(output_path)\n",
    "    save_dataset(df_pos, df_neg, test_path)\n",
    "    print('Test saved to: \"{}\"'.format(test_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "platform = Platform.GCP\n",
    "profile = PySparkJobProfile(root_path='demo/scripts',\n",
    "                                  bucket='ai4ops',\n",
    "                                  project='gd-gcp-techlead-experiments',\n",
    "                                  cluster='ai4ops',\n",
    "                                  region='global',\n",
    "                                  ai_region='us-central1-a',\n",
    "                                  job_prefix='demo_job',\n",
    "                                  job_async=False)\n",
    "profile.args=profile.load_profile_data(\"demo/spark_job_args_gcp.json\")\n",
    "PySparkJobProfile.set('JobProfile', profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters string = <<<-n text_tokenizer.py -p JobProfile -pm 1 -o gs://ai4ops/mldsl/data>>>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href=\"https://console.cloud.google.com/dataproc/jobs/demo_job_1592575205?project=gd-gcp-techlead-experiments&region=global\">demo_job_1592575205</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job with id demo_job_1592575205 was submitted to the cluster ai4ops\n",
      "Job STATUS was set to DONE at 2020-06-19 14:01:42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href=\"https://console.cloud.google.com/storage/browser/ai4ops/mldsl/data/demo_job_1592575205?project=gd-gcp-techlead-experiments\">Output Data demo_job_1592575205</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "driver_control_files_uri": "gs://ai4ops/google-cloud-dataproc-metainfo/2d057403-a13f-40fa-b785-43cf3d7e2bc3/jobs/demo_job_1592575205/",
       "driver_output_resource_uri": "gs://ai4ops/google-cloud-dataproc-metainfo/2d057403-a13f-40fa-b785-43cf3d7e2bc3/jobs/demo_job_1592575205/driveroutput",
       "labels": {},
       "placement": {
        "cluster_name": "ai4ops"
       },
       "pyspark_job": {
        "archive_uris": [],
        "args": [
         "--output_path",
         "gs://ai4ops/mldsl/data/demo_job_1592575205",
         "--train_path",
         "gs://ai4ops/mldsl/data/aclImdb/train",
         "--test_path",
         "gs://ai4ops/mldsl/data/aclImdb/test",
         "--word_embeds",
         "gs://ai4ops/mldsl/data/glove.6B.50d.txt"
        ],
        "file_uris": [],
        "jar_file_uris": [],
        "logging_config": {
         "driver_log_levels": {}
        },
        "main_python_file_uri": "gs://ai4ops/jobs-root/demo_job_1592575205/text_tokenizer.py",
        "properties": {},
        "python_file_uris": [
         "gs://ai4ops/jobs-root/demo_job_1592575205/text_tokenizer.py"
        ]
       },
       "reference": {
        "job_id": "demo_job_1592575205",
        "project_id": "gd-gcp-techlead-experiments"
       },
       "scheduling": {
        "max_failures_per_hour": 0
       },
       "start_time": "2020-06-19T14:01:42.000000",
       "status": "DONE",
       "yarn_applications": [
        {
         "name": "word_tokenizer",
         "progress": 1,
         "state": "FINISHED",
         "trackingUrl": "http://ai4ops-m:8088/proxy/application_1590766736446_0008/"
        }
       ]
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%py_data -n text_tokenizer.py -p JobProfile -pm $platform -o gs://ai4ops/mldsl/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use job_demo_job_1592575205 instance to browse job properties.\n",
    "#job_demo_job_1592575205 = job_tracker['demo_job_1592575205']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Model to Predict Positive or Negative Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Additional Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Train Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporary path: /home/jovyan/work/data/.mldsl/mr_model.py\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<com.griddynamics.dsl.ml.py_script.PyScript at 0x7f73bb3ef550>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%py_script -n mr_model.py -p demo/model/words/trainer -o dev/models --epochs 3 --train_path gs://ai4ops/mldsl/data/demo_job_1590767199/train --word_embeds gs://ai4ops/mldsl/data/demo_job_1590767199/words --seq_len 150\n",
    "#!/usr/bin/python\n",
    "\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from tensorflow.python.lib.io import file_io\n",
    "    from tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "    from tensorflow.keras.models import Model\n",
    "    from tensorflow.keras.callbacks import Callback\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "    import tensorflow as tf\n",
    "    import os\n",
    "\n",
    "    from uuid import uuid4\n",
    "    import argparse\n",
    "    import matplotlib\n",
    "    if matplotlib.get_backend() in ['TkAgg', 'TkCairo']:\n",
    "        matplotlib.use('agg')\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "\n",
    "class MetricCallback(Callback):\n",
    "    def on_train_begin(self,logs={}):\n",
    "        self.losses = []\n",
    "        self.accuracies = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.accuracies.append(logs.get('acc'))\n",
    "\n",
    "\n",
    "def read_glove_vectors(glove_file):\n",
    "    files = file_io.get_matching_files('{}/part*'.format(glove_file))\n",
    "    for file in files:\n",
    "        with file_io.FileIO(file, 'r') as f:\n",
    "            word_to_vec_map = {}\n",
    "            words_to_index = {}\n",
    "        fl = f.readline()\n",
    "        for line in f:\n",
    "            line = line.strip().split('\\t')\n",
    "            word_to_vec_map[line[0]] = np.array(line[1].split(','), dtype=np.float64)\n",
    "            words_to_index[line[0]] = int(line[2])\n",
    "    return words_to_index, word_to_vec_map\n",
    "\n",
    "\n",
    "def read_csv(path):\n",
    "    files = file_io.get_matching_files('{}/part*'.format(path))\n",
    "    pdf = []\n",
    "    for file in files:\n",
    "        with file_io.FileIO(file, 'r') as f:\n",
    "            df = pd.read_csv(f)\n",
    "            if df is not None and len(df) != 0:\n",
    "                pdf.append(df)\n",
    "    if len(pdf) == 0:\n",
    "        return None\n",
    "    return pd.concat(pdf, axis=0, ignore_index=True).reset_index()\n",
    "\n",
    "\n",
    "def pretrained_embed_layer(word_to_vec_map, word_to_index, emb_dim):\n",
    "    emb_matrix = np.zeros((len(word_to_index)+1, emb_dim))\n",
    "    for word, idx in word_to_index.items():\n",
    "        emb_matrix[idx, :] = word_to_vec_map[word]\n",
    "    \n",
    "    return emb_matrix\n",
    "\n",
    "\n",
    "def define_model(input_shape, emb_matrix, vocab_len, emb_dim, rnn_units, dropout=0.5):\n",
    "    sentence_indices = Input(input_shape, dtype=\"int32\")\n",
    "    # Create the embedding layer pretrained with GloVe Vectors\n",
    "    embedding_layer = Embedding(input_dim=vocab_len, trainable=False, output_dim=emb_dim)\n",
    "    embedding_layer.build((None,))\n",
    "    embedding_layer.set_weights([emb_matrix])\n",
    "    # Propagate sentence_indices through your embedding layer\n",
    "    embeddings = embedding_layer(sentence_indices)\n",
    "    X = LSTM(units=rnn_units, return_sequences=False)(embeddings)\n",
    "    # Add dropout with a probability \n",
    "    X = Dropout(dropout)(X)\n",
    "    # Propagate X through a Dense layer\n",
    "    X = Dense(2)(X)\n",
    "    # Add a softmax activation\n",
    "    X = Activation(\"softmax\")(X)\n",
    "    # Create Model instance which converts sentence_indices into X.\n",
    "    model = Model(inputs=sentence_indices, outputs=X)\n",
    "    return model\n",
    "\n",
    "\n",
    "def convert_to_one_hot(Y, C=2):\n",
    "    Y = np.eye(C)[Y.reshape(-1)]\n",
    "    return Y\n",
    "\n",
    "def prepare_dataset(path, N, word_to_index):\n",
    "    data = read_csv(path)\n",
    "    data.dropna(inplace=True)\n",
    "    data['int_seq'] = data['int_seq'].apply(lambda x: [int(i) for i in x.split(',')])\n",
    "    l = data['int_seq'].apply(lambda x: len(x))\n",
    "    print(\"Max sequence is set to {}\".format(N))\n",
    "    data['int_seq'] = data['int_seq'].apply(lambda x: (x + [word_to_index[\"unk\"]] * N)[:N])\n",
    "    ds_x = np.asarray(list(data[\"int_seq\"]))\n",
    "    ds_y = data[\"class\"].values\n",
    "    return ds_x, ds_y, l\n",
    "\n",
    "\n",
    "def plot_metrics(callback, dir_to_save):\n",
    "    f, axes = plt.subplots(1, 2, figsize=(18, 5))\n",
    "    plt.style.use('seaborn')\n",
    "    plt.rcParams['axes.titlesize'] = 16\n",
    "    sns.lineplot(x=range(len(callback.losses)), y=callback.losses, ax=axes[0])\n",
    "    axes[0].title.set_text(\"Loss\")\n",
    "    sns.lineplot(x=range(len(callback.accuracies)), y=callback.accuracies, ax=axes[1])\n",
    "    axes[1].title.set_text(\"Accuracy\")\n",
    "    plt.tight_layout(.5)\n",
    "    plt.savefig('{}'.format(dir_to_save))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--train_path', type=str, help=\"Train files path\")\n",
    "    parser.add_argument('--output_path', type=str, help=\"Models output path\")\n",
    "    parser.add_argument('--word_embeds', type=str, help=\"Models output path\")\n",
    "    parser.add_argument('--seq_len', type=int, help=\"Length of input sequence\")\n",
    "    parser.add_argument('--epochs', type=int, help=\"Number of epochs\")\n",
    "    args, d = parser.parse_known_args()\n",
    "\n",
    "    word_to_index, word_to_vec_map = read_glove_vectors(args.word_embeds)\n",
    "    N = args.seq_len\n",
    "    train_x, train_y, l = prepare_dataset(args.train_path, N, word_to_index)\n",
    "    train_y = convert_to_one_hot(train_y, C=2)\n",
    "    NUM_EPOCS = args.epochs\n",
    "    RNN_STATE_DIM = 32\n",
    "    LEARNING_RATE = 0.01\n",
    "    vocab_len = len(word_to_index) + 1\n",
    "    emb_dim = word_to_vec_map[\"cucumber\"].shape[0]\n",
    "    emb_matrix = pretrained_embed_layer(word_to_vec_map, word_to_index, emb_dim)\n",
    "\n",
    "    model = define_model((N, ), emb_matrix, vocab_len, emb_dim, RNN_STATE_DIM)\n",
    "    print(model.summary())\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=LEARNING_RATE), metrics=['accuracy'])\n",
    "    # fit model\n",
    "    metrics = MetricCallback()\n",
    "    a = model.fit(train_x, train_y, batch_size=1024, epochs=NUM_EPOCS, callbacks=[metrics], \n",
    "                  shuffle=True)\n",
    "\n",
    "    tf.get_logger().setLevel('ERROR')\n",
    "    # save the model to file\n",
    "    local_dir = uuid4().hex\n",
    "    file_io.recursive_create_dir(local_dir)\n",
    "    local_path = f'{local_dir}/saved_model'\n",
    "    tf.saved_model.save(model, local_path)\n",
    "    local_path_chart = '{}/metrics.png'.format(local_dir)\n",
    "    plot_metrics(metrics, local_path_chart)\n",
    "    \n",
    "    remote_dir = args.output_path\n",
    "    remote_path = f'{remote_dir}/saved_model'\n",
    "    remote_path_chart = f'{remote_dir}/metrics.png'\n",
    "    if not remote_dir.startswith('gs://'):\n",
    "        file_io.recursive_create_dir(remote_dir)\n",
    "    file_io.copy(local_path_chart, remote_path_chart)\n",
    "    tf.saved_model.save(model, remote_path)\n",
    "    \n",
    "    file_io.delete_recursively(local_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "platform = Platform.GCP\n",
    "profile = AIProfile(bucket='ai4ops', cluster='ai4ops', region='global', job_prefix='train',\n",
    "                    root_path='demo/model/words', \n",
    "                    project='gd-gcp-techlead-experiments',\n",
    "                    ai_region='us-central1', job_async=False,\n",
    "                    package_name='trainer', package_dst='mldsl/packages',\n",
    "                    scale_tier='BASIC', runtime_version='1.15', python_version='3.7')\n",
    "profile.arguments = profile.load_profile_data(\"demo/train_args.json\")\n",
    "AIProfile.set('AIProfile', profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporary path: /home/jovyan/work/data/.mldsl/setup.py\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<com.griddynamics.dsl.ml.py_script.PyScript at 0x7f73b898b9e8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%py_script --name setup.py --path demo/model/words\n",
    "# %py_load demo/model/words/setup.py\n",
    "#!/usr/bin/python\n",
    "from setuptools import setup, find_packages\n",
    "\n",
    "REQUIRED_PACKAGES = ['Keras==2.0.4','matplotlib==2.2.4','seaborn==0.9.0']\n",
    "\n",
    "setup(\n",
    "    name='trainer',\n",
    "    version='1.0',\n",
    "    packages=find_packages(),\n",
    "    install_requires=REQUIRED_PACKAGES,\n",
    "    author='Grid Dynamics ML Engineer',\n",
    "    author_email='griddynamics@griddynamics.com',\n",
    "    url='https://griddynamics.com'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"https://console.cloud.google.com/ai-platform/jobs/train_1593085765/charts/cpu?project=gd-gcp-techlead-experiments\">train_1593085765</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running sdist\n",
      "running egg_info\n",
      "writing trainer.egg-info/PKG-INFO\n",
      "writing dependency_links to trainer.egg-info/dependency_links.txt\n",
      "writing requirements to trainer.egg-info/requires.txt\n",
      "writing top-level names to trainer.egg-info/top_level.txt\n",
      "reading manifest file 'trainer.egg-info/SOURCES.txt'\n",
      "writing manifest file 'trainer.egg-info/SOURCES.txt'\n",
      "running check\n",
      "creating trainer-1.0\n",
      "creating trainer-1.0/trainer\n",
      "creating trainer-1.0/trainer.egg-info\n",
      "copying files to trainer-1.0...\n",
      "copying README.md -> trainer-1.0\n",
      "copying setup.py -> trainer-1.0\n",
      "copying trainer/__init__.py -> trainer-1.0/trainer\n",
      "copying trainer/mr_model.py -> trainer-1.0/trainer\n",
      "copying trainer.egg-info/PKG-INFO -> trainer-1.0/trainer.egg-info\n",
      "copying trainer.egg-info/SOURCES.txt -> trainer-1.0/trainer.egg-info\n",
      "copying trainer.egg-info/dependency_links.txt -> trainer-1.0/trainer.egg-info\n",
      "copying trainer.egg-info/requires.txt -> trainer-1.0/trainer.egg-info\n",
      "copying trainer.egg-info/top_level.txt -> trainer-1.0/trainer.egg-info\n",
      "Writing trainer-1.0/setup.cfg\n",
      "Creating tar archive\n",
      "removing 'trainer-1.0' (and everything under it)\n",
      "Uploading custom package demo/model/words/dist/trainer-1.0.tar.gz to dir gs://ai4ops/mldsl/packages/train_1593085765/trainer-1.0.tar.gz\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href=\"https://console.cloud.google.com/storage/browser/ai4ops/mldsl/train_1593085765?project=gd-gcp-techlead-experiments\">Output Data train_1593085765</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "createTime": "2020-06-25T11:49:26Z",
       "endTime": "2020-06-25T12:01:48Z",
       "etag": "OM3W4sCz8J8=",
       "jobId": "train_1593085765",
       "startTime": "2020-06-25T11:50:12Z",
       "state": "SUCCEEDED",
       "trainingInput": {
        "args": [
         "--train_path",
         "gs://ai4ops/mldsl/data/demo_job_1590767199/train",
         "--word_embeds",
         "gs://ai4ops/mldsl/data/demo_job_1590767199/words",
         "--seq_len",
         "150",
         "--epochs",
         "40",
         "-s",
         "demo/model/words",
         "--output_path",
         "gs://ai4ops/mldsl/train_1593085765"
        ],
        "jobDir": "gs://ai4ops/mldsl/train_1593085765",
        "packageUris": [
         "gs://ai4ops/mldsl/packages/train_1593085765/trainer-1.0.tar.gz"
        ],
        "pythonModule": "trainer.mr_model",
        "pythonVersion": "3.7",
        "region": "us-central1",
        "runtimeVersion": "1.15"
       },
       "trainingOutput": {
        "consumedMLUnits": 0.06
       }
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%py_train -n mr_model.py -s demo/model/words -p AIProfile -pm $platform -o gs://ai4ops/mldsl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment of model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Parameters of deployment: name of model, version, artifacts (models saved as .joblib, .h5 etc), custom code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "platform = Platform.GCP\n",
    "profile = DeployAIProfile(bucket='ai4ops', cluster='ai4ops', region='global', job_prefix='deploy',\n",
    "                          root_path='demo/deploy', project='gd-gcp-techlead-experiments',\n",
    "                          ai_region='us-central1', job_async=False,\n",
    "                          runtime_version='1.15', python_version='3.7',\n",
    "                          version_name='v1', is_new_model=True,\n",
    "                          path_to_saved_model='gs://ai4ops/mldsl/train_1592767608/saved_model/')\n",
    "profile.arguments = {\n",
    "    \"framework\": \"TENSORFLOW\"\n",
    "}\n",
    "DeployAIProfile.set('AIProfile', profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"https://console.cloud.google.com/storage/browser/ai4ops/mldsl/train_1592767608/saved_model/?project=gd-gcp-techlead-experiments\">Deploy model path deploy_1593103768</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "createTime": "2020-06-25T16:49:29Z",
       "deploymentUri": "gs://ai4ops/mldsl/train_1592767608/saved_model/",
       "etag": "vs4ct8XCDFo=",
       "framework": "TENSORFLOW",
       "isDefault": true,
       "machineType": "mls1-c1-m2",
       "name": "projects/gd-gcp-techlead-experiments/models/mldsl/versions/v1",
       "pythonVersion": "3.7",
       "runtimeVersion": "1.15",
       "state": "READY"
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%py_deploy -n mldsl -p AIProfile -pm $platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use job_deploy_1593103768 instance to browse job properties.\n",
    "#job_tracker['deploy_1593103768']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sequence is set to 150\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    from utils import *\n",
    "\n",
    "word_to_index, word_to_vec_map = read_glove_vectors(\"gs://ai4ops/mldsl/data/demo_job_1590767199/words\")\n",
    "df_x, df_y, l = prepare_dataset('gs://ai4ops/mldsl/data/demo_job_1590767199/test', 150, word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ints = np.random.choice(len(df_y), 100)\n",
    "\n",
    "test_x = df_x[ints]\n",
    "test_y = df_y[ints]\n",
    "test = test_x.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%py_test -n mldsl -p AIProfile -pm $platform -t $test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation=[[0.6321429014205933, 0.3678571879863739], [0.12713439762592316, 0.872865617275238], [0.024109704419970512, 0.9758903384208679], [0.003592864843085408, 0.9964070916175842], [0.9954433441162109, 0.004556715488433838], [0.9952955842018127, 0.004704390186816454], [0.005713205318897963, 0.994286835193634], [0.7208364009857178, 0.2791635990142822], [0.8376214504241943, 0.16237856447696686], [0.007366553880274296, 0.9926334023475647], [0.9722245335578918, 0.02777550183236599], [0.17860515415668488, 0.8213948011398315], [0.01433265209197998, 0.9856674075126648], [0.9497862458229065, 0.05021375045180321], [0.016234956681728363, 0.9837650656700134], [0.8964889049530029, 0.10351112484931946], [0.6874122023582458, 0.31258782744407654], [0.9943034648895264, 0.0056966147385537624], [0.9732365608215332, 0.02676350623369217], [0.1060587540268898, 0.8939412832260132], [0.9830858707427979, 0.01691410318017006], [0.8533444404602051, 0.14665552973747253], [0.008659862913191319, 0.9913401007652283], [0.15943501889705658, 0.8405649662017822], [0.4126940369606018, 0.5873059630393982], [0.005080858711153269, 0.9949191212654114], [0.9920275807380676, 0.007972449995577335], [0.3200126886367798, 0.6799872517585754], [0.9934780597686768, 0.0065219649113714695], [0.17479296028614044, 0.8252071142196655], [0.005040396470576525, 0.9949595928192139], [0.9938644766807556, 0.006135530304163694], [0.1501808762550354, 0.8498191237449646], [0.006657484453171492, 0.9933425784111023], [0.9937819838523865, 0.006217994261533022], [0.0026067732833325863, 0.9973932504653931], [0.7288512587547302, 0.2711487412452698], [0.9950405955314636, 0.004959406331181526], [0.9918374419212341, 0.008162522688508034], [0.03815029561519623, 0.9618497490882874], [0.9279369115829468, 0.07206311821937561], [0.4548940062522888, 0.5451059937477112], [0.9859738349914551, 0.014026147313416004], [0.717399001121521, 0.2826010584831238], [0.9061329960823059, 0.09386692196130753], [0.008032294921576977, 0.9919677376747131], [0.1301707625389099, 0.8698292374610901], [0.03836825117468834, 0.9616317749023438], [0.9717956185340881, 0.02820434421300888], [0.9852221608161926, 0.014777859672904015], [0.028501763939857483, 0.9714981913566589], [0.34971481561660767, 0.6502852439880371], [0.38276126980781555, 0.6172387003898621], [0.010509427636861801, 0.9894905686378479], [0.817579984664917, 0.18241997063159943], [0.042655665427446365, 0.9573442935943604], [0.04805301874876022, 0.9519469738006592], [0.454426109790802, 0.545573890209198], [0.05582763999700546, 0.9441723823547363], [0.723135769367218, 0.276864230632782], [0.09276805818080902, 0.9072319865226746], [0.004389461595565081, 0.9956105351448059], [0.9838841557502747, 0.016115805134177208], [0.005091487895697355, 0.9949085116386414], [0.8129076957702637, 0.1870923638343811], [0.9876847267150879, 0.01231524907052517], [0.9725201725959778, 0.02747986651957035], [0.15392236411571503, 0.8460776805877686], [0.49223628640174866, 0.5077638030052185], [0.08798418194055557, 0.9120157957077026], [0.17651809751987457, 0.8234819173812866], [0.05052492022514343, 0.949475109577179], [0.9047545194625854, 0.09524549543857574], [0.002965514548122883, 0.9970344305038452], [0.04132595658302307, 0.9586740732192993], [0.9963577389717102, 0.003642183030024171], [0.005217075813561678, 0.9947828650474548], [0.41338545083999634, 0.5866145491600037], [0.06867239624261856, 0.9313275814056396], [0.8458981513977051, 0.15410184860229492], [0.9945433139801025, 0.005456637125462294], [0.024829810485243797, 0.9751701951026917], [0.8619129061698914, 0.13808707892894745], [0.9948599338531494, 0.005140069406479597], [0.5833669304847717, 0.41663309931755066], [0.9939045310020447, 0.006095414981245995], [0.005308421794325113, 0.9946915507316589], [0.9916778802871704, 0.008322128094732761], [0.9943532943725586, 0.005646682344377041], [0.4925752282142639, 0.5074247717857361], [0.030627448111772537, 0.969372570514679], [0.9161972999572754, 0.08380267024040222], [0.996094286441803, 0.0039057156536728144], [0.9912528395652771, 0.008747115731239319], [0.0869859904050827, 0.9130139946937561], [0.9876487851142883, 0.012351155281066895], [0.9654543399810791, 0.0345456562936306], [0.17442718148231506, 0.8255727887153625], [0.9880678653717041, 0.01193215698003769], [0.9955512285232544, 0.004448742605745792]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds=np.array(activation).argmax(axis=1)\n",
    "conf_mat = confusion_matrix(test_y, preds)\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "classes=['Negative', 'Positive']\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d',xticklabels=classes, yticklabels=classes, cmap=plt.cm.BuGn)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "negative review       0.92      0.90      0.91        50\n",
      "positive review       0.90      0.92      0.91        50\n",
      "\n",
      "       accuracy                           0.91       100\n",
      "      macro avg       0.91      0.91      0.91       100\n",
      "   weighted avg       0.91      0.91      0.91       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['negative review', 'positive review']\n",
    "print(classification_report(test_y, preds, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
